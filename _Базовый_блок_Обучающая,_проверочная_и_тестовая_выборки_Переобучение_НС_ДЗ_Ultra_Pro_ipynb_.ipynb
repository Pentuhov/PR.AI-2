{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pentuhov/PR.AI-2/blob/main/_%D0%91%D0%B0%D0%B7%D0%BE%D0%B2%D1%8B%D0%B9_%D0%B1%D0%BB%D0%BE%D0%BA_%D0%9E%D0%B1%D1%83%D1%87%D0%B0%D1%8E%D1%89%D0%B0%D1%8F%2C_%D0%BF%D1%80%D0%BE%D0%B2%D0%B5%D1%80%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%B8_%D1%82%D0%B5%D1%81%D1%82%D0%BE%D0%B2%D0%B0%D1%8F_%D0%B2%D1%8B%D0%B1%D0%BE%D1%80%D0%BA%D0%B8_%D0%9F%D0%B5%D1%80%D0%B5%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D0%9D%D0%A1_%D0%94%D0%97_Ultra_Pro_ipynb_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DJmI3d5WqQUb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2pH_8ASEy09"
      },
      "source": [
        "Используя базу \"Пассажиры автобуса\", подготовьте данные для обучения нейронной сети, классифицирующей изображение на два класса:\n",
        "- входящий пассажир\n",
        "- выходящий пассажир\n",
        "\n",
        "Добейтесь точности работы модели на проверочной выборке не ниже 85%\n",
        "\n",
        "Ссылка на датасет: https://storage.yandexcloud.net/aiueducation/Content/base/l4/bus.zip\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Информацию о загрузке изображений и преобразовании их в numnpy-массивы вы можете найти в Базе знаний:"
      ],
      "metadata": {
        "id": "u9YCGl-gMuLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gdown\n",
        "import os\n",
        "import pdb\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "M8MRyxqwniza"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/Входящий') or not os.path.exists('/content/Выходящий'):\n",
        "\n",
        "  gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l4/bus.zip', None, quiet = True)\n",
        "\n",
        "  with zipfile.ZipFile('bus.zip', 'r') as zip_file:\n",
        "      zip_file.extractall('/content')"
      ],
      "metadata": {
        "id": "Rz4-fm16ngtR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8JyVKClnT3B",
        "outputId": "ceddee5b-e82f-46da-dc99-f3c5dfe3e980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.5878 - loss: 0.9357 - val_accuracy: 0.7226 - val_loss: 0.5632\n",
            "Epoch 2/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.7169 - loss: 0.6012 - val_accuracy: 0.7199 - val_loss: 0.5294\n",
            "Epoch 3/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - accuracy: 0.7614 - loss: 0.5215 - val_accuracy: 0.7977 - val_loss: 0.4643\n",
            "Epoch 4/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.7831 - loss: 0.4721 - val_accuracy: 0.8390 - val_loss: 0.4176\n",
            "Epoch 5/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.8009 - loss: 0.4360 - val_accuracy: 0.7213 - val_loss: 0.5585\n",
            "Epoch 6/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.8128 - loss: 0.4187 - val_accuracy: 0.8396 - val_loss: 0.3853\n",
            "Epoch 7/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.8200 - loss: 0.4089 - val_accuracy: 0.8211 - val_loss: 0.4390\n",
            "Epoch 8/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.8159 - loss: 0.4029 - val_accuracy: 0.8314 - val_loss: 0.4118\n",
            "Epoch 9/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 65ms/step - accuracy: 0.8116 - loss: 0.4189 - val_accuracy: 0.8080 - val_loss: 0.3986\n",
            "Epoch 10/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.8281 - loss: 0.3867 - val_accuracy: 0.8534 - val_loss: 0.3590\n",
            "Epoch 11/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.8216 - loss: 0.4002 - val_accuracy: 0.8114 - val_loss: 0.4225\n",
            "Epoch 12/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 65ms/step - accuracy: 0.8292 - loss: 0.3855 - val_accuracy: 0.7557 - val_loss: 0.4713\n",
            "Epoch 13/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.8348 - loss: 0.3800 - val_accuracy: 0.8369 - val_loss: 0.3402\n",
            "Epoch 14/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 0.8297 - loss: 0.3857 - val_accuracy: 0.8410 - val_loss: 0.3452\n",
            "Epoch 15/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.8302 - loss: 0.3812 - val_accuracy: 0.8197 - val_loss: 0.3592\n",
            "Epoch 16/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.8361 - loss: 0.3721 - val_accuracy: 0.8045 - val_loss: 0.4263\n",
            "Epoch 17/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.8390 - loss: 0.3615 - val_accuracy: 0.8355 - val_loss: 0.3616\n",
            "Epoch 18/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.8405 - loss: 0.3618 - val_accuracy: 0.8541 - val_loss: 0.3172\n",
            "Epoch 19/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.8452 - loss: 0.3627 - val_accuracy: 0.8328 - val_loss: 0.3567\n",
            "Epoch 20/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - accuracy: 0.8470 - loss: 0.3435 - val_accuracy: 0.8644 - val_loss: 0.3158\n",
            "Epoch 21/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.8458 - loss: 0.3409 - val_accuracy: 0.8802 - val_loss: 0.2859\n",
            "Epoch 22/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.8517 - loss: 0.3316 - val_accuracy: 0.8445 - val_loss: 0.3255\n",
            "Epoch 23/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.8420 - loss: 0.3495 - val_accuracy: 0.8679 - val_loss: 0.3228\n",
            "Epoch 24/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.8556 - loss: 0.3301 - val_accuracy: 0.7075 - val_loss: 0.5186\n",
            "Epoch 25/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.8511 - loss: 0.3336 - val_accuracy: 0.8651 - val_loss: 0.3002\n",
            "Epoch 26/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.8481 - loss: 0.3391 - val_accuracy: 0.8768 - val_loss: 0.2813\n",
            "Epoch 27/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.8428 - loss: 0.3584 - val_accuracy: 0.8665 - val_loss: 0.3172\n",
            "Epoch 28/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.8444 - loss: 0.3624 - val_accuracy: 0.8424 - val_loss: 0.3537\n",
            "Epoch 29/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.8332 - loss: 0.3829 - val_accuracy: 0.8286 - val_loss: 0.3786\n",
            "Epoch 30/30\n",
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8246 - loss: 0.3998 - val_accuracy: 0.8362 - val_loss: 0.3946\n",
            "Точность на обучающем наборе: 84.63%\n",
            "Точность на проверочном наборе: 83.62%\n",
            "Точность на тестовом наборе: 84.98%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "# Пути к каталогам с изображениями\n",
        "input_dir = '/content/Входящий'\n",
        "output_dir = '/content/Выходящий'\n",
        "\n",
        "# Функция для загрузки и предобработки изображений\n",
        "def load_images(directory):\n",
        "    images = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.jpg'):\n",
        "            img = Image.open(os.path.join(directory, filename))\n",
        "            img = img.resize((100, 100))  # Подгоняем размер изображения по необходимости\n",
        "            img = np.array(img) / 255.0  # Нормализуем изображение\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "# Загрузка изображений и создание меток классов\n",
        "input_images = load_images(input_dir)\n",
        "output_images = load_images(output_dir)\n",
        "X = np.array(input_images + output_images)\n",
        "y = np.array([0] * len(input_images) + [1] * len(output_images))  # 0 для входящего, 1 для выходящего\n",
        "\n",
        "# Разделение данных на обучающий, проверочный и тестовый наборы\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Нормализация\n",
        "X_train_normalized = X_train.reshape(X_train.shape[0], -1).astype('float32') / 255.0\n",
        "X_val_normalized = X_val.reshape(X_val.shape[0], -1).astype('float32') / 255.0\n",
        "X_test_normalized = X_test.reshape(X_test.shape[0], -1).astype('float32') / 255.0\n",
        "y_train_categorical = utils.to_categorical(y_train, 2)\n",
        "y_val_categorical = utils.to_categorical(y_val, 2)\n",
        "y_test_categorical = utils.to_categorical(y_test, 2)\n",
        "\n",
        "# Создание модели\n",
        "def create_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Создание и компиляция модели\n",
        "model = create_model(input_shape=X_train_normalized.shape[1:])\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "history = model.fit(\n",
        "    X_train_normalized,\n",
        "    y_train_categorical,\n",
        "    validation_data=(X_val_normalized, y_val_categorical),\n",
        "    epochs=30,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Оценка точности на обучающем, проверочном и тестовом наборах\n",
        "train_loss, train_accuracy = model.evaluate(X_train_normalized, y_train_categorical, verbose=0)\n",
        "val_loss, val_accuracy = model.evaluate(X_val_normalized, y_val_categorical, verbose=0)\n",
        "test_loss, test_accuracy = model.evaluate(X_test_normalized, y_test_categorical, verbose=0)\n",
        "\n",
        "print(\"Точность на обучающем наборе: {:.2f}%\".format(train_accuracy * 100))\n",
        "print(\"Точность на проверочном наборе: {:.2f}%\".format(val_accuracy * 100))\n",
        "print(\"Точность на тестовом наборе: {:.2f}%\".format(test_accuracy * 100))\n",
        "\n"
      ]
    }
  ]
}